{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path = './train_data_after_pre.csv'\n",
    "test_file_path = './test_data_after_pre.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    data.head()\n",
    "    X = data.content\n",
    "    Y = data.target\n",
    "    return X, Y\n",
    "\n",
    "X, Y = load_csv(train_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label = {'positive':1, 'negative':-1}\n",
    "\n",
    "# def preprocess_y(sentiment):\n",
    "#     return label[sentiment]\n",
    "\n",
    "# y = y.apply(preprocess_y)\n",
    "# y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    atlantis lost empire better movie thought neve...\n",
       "1    wonderful film version bestselling book smash ...\n",
       "2    sent prison le 10 40 year busted drug refusing...\n",
       "3    bar none hilarious movie ever seen beginning f...\n",
       "4    rather good movie americanised predictability ...\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/wanghengchao/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    atlantis lost empire better movie thought neve...\n",
       "1    wonderful film version bestselling book smash ...\n",
       "2    sent prison le 10 40 year busted drug refusing...\n",
       "3    bar none hilarious movie ever seen beginning f...\n",
       "4    rather good movie americanised predictability ...\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def preprocess(review):\n",
    "    #convert the tweet to lower case\n",
    "    review.lower()\n",
    "    #convert all urls to sting \"URL\"\n",
    "    review = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','URL',review)\n",
    "    #convert all @username to \"AT_USER\"\n",
    "    review = re.sub('@[^\\s]+','AT_USER', review)\n",
    "    #correct all multiple white spaces to a single white space\n",
    "    review = re.sub('[\\s]+', ' ', review)\n",
    "    #convert \"#topic\" to just \"topic\"\n",
    "    review = re.sub(r'#([^\\s]+)', r'\\1', review)\n",
    "    tokens = word_tokenize(review)\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "X = X.apply(preprocess)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2641)\t0.16341453880947646\n",
      "  (0, 95261)\t0.12246356610044269\n",
      "  (0, 4958)\t0.10562382004472992\n",
      "  (0, 41846)\t0.08757288118911812\n",
      "  (0, 85637)\t0.10678315419247991\n",
      "  (0, 49945)\t0.08526602790264595\n",
      "  (0, 13701)\t0.06764369661229365\n",
      "  (0, 7334)\t0.12264702703006267\n",
      "  (0, 68495)\t0.13570427598810866\n",
      "  (0, 109632)\t0.093199350861385\n",
      "  (0, 78982)\t0.08708889002879584\n",
      "  (0, 115122)\t0.10683262260610758\n",
      "  (0, 19873)\t0.1272228587845625\n",
      "  (0, 65410)\t0.06539732586794086\n",
      "  (0, 114025)\t0.1316637924488914\n",
      "  (0, 50832)\t0.060988817011347535\n",
      "  (0, 20098)\t0.07806878688785383\n",
      "  (0, 126351)\t0.18561920291698983\n",
      "  (0, 121339)\t0.13854515501675002\n",
      "  (0, 13811)\t0.17613929219192448\n",
      "  (0, 46673)\t0.1414523233478071\n",
      "  (0, 37939)\t0.2225921565596288\n",
      "  (0, 127632)\t0.060760143947124846\n",
      "  (0, 4464)\t0.12325255770879875\n",
      "  (0, 6544)\t0.1056002189701825\n",
      "  :\t:\n",
      "  (24999, 76243)\t0.14823796441277381\n",
      "  (24999, 31605)\t0.12539527184487945\n",
      "  (24999, 109153)\t0.10248865545395464\n",
      "  (24999, 41585)\t0.13358966417236628\n",
      "  (24999, 20763)\t0.10486151062637716\n",
      "  (24999, 126767)\t0.12434601848223238\n",
      "  (24999, 121633)\t0.09072348098664189\n",
      "  (24999, 21135)\t0.09502400819895922\n",
      "  (24999, 3887)\t0.06945952700618445\n",
      "  (24999, 22594)\t0.10710861835971795\n",
      "  (24999, 32037)\t0.07872530662339126\n",
      "  (24999, 101542)\t0.08498611870453338\n",
      "  (24999, 127349)\t0.11368322857398179\n",
      "  (24999, 83438)\t0.10961360421872889\n",
      "  (24999, 75706)\t0.08462093649855632\n",
      "  (24999, 34278)\t0.06335239340319944\n",
      "  (24999, 11115)\t0.1107521558181597\n",
      "  (24999, 121386)\t0.08608265560484482\n",
      "  (24999, 51981)\t0.050529846334962554\n",
      "  (24999, 126581)\t0.0643537538831827\n",
      "  (24999, 95261)\t0.12700415375835528\n",
      "  (24999, 49945)\t0.0884274406089887\n",
      "  (24999, 46626)\t0.08806117664004298\n",
      "  (24999, 77732)\t0.09126447916412307\n",
      "  (24999, 13833)\t0.07169814403852597\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "def feature_extraction(data):\n",
    "    tfv=TfidfVectorizer(sublinear_tf=True, stop_words = \"english\")\n",
    "    features=tfv.fit_transform(data)\n",
    "    pickle.dump(tfv.vocabulary_, open(\"svm_feature.pkl\", \"wb\"))\n",
    "    return features\n",
    "\n",
    "data = np.array(X)\n",
    "label = np.array(Y)\n",
    "features = feature_extraction(data)\n",
    "\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<20000x132911 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1749833 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(features, label, test_size = 0.20) \n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC  \n",
    "svclassifier = SVC(kernel='linear')  \n",
    "\n",
    "svclassifier.fit(features, label)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 0 0 1]\n",
      "0.86104\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "val_pred = svclassifier.predict(X_test)\n",
    "print(val_pred)\n",
    "print(accuracy_score(Y_test, val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'svm_model.sav'\n",
    "pickle.dump(svclassifier, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "X_test1,Y_test1 = load_csv(test_file_path)\n",
    "data_test = np.array(X_test1)\n",
    "label_test = np.array(Y_test1)\n",
    "transformer = TfidfTransformer()\n",
    "tfv_loaded = TfidfVectorizer(sublinear_tf=True, stop_words = \"english\", vocabulary=pickle.load(open(\"svm_feature.pkl\", \"rb\")))\n",
    "features_test = transformer.fit_transform(tfv_loaded.fit_transform(data_test))\n",
    "X_test1,Y_test1 = features_test, label_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.86104\n"
     ]
    }
   ],
   "source": [
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "val_pred_test = loaded_model.predict(X_test1)\n",
    "print(accuracy_score(Y_test1, val_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
